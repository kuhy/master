#+TITLE: Pull request analysis
#+AUTHOR: Ond≈ôej Kuhejda
#+PROPERTY: header-args+ :comments both
#+PROPERTY: header-args+ :tangle "pr_analysis.R"
* Packages
  Following packages are needed for data manipulation:
  #+BEGIN_SRC R
    # install.packages("tidyverse")
    library("dplyr")
    library("purrr")
  #+END_SRC

  This package is needed for PCA plotting:
  #+BEGIN_SRC R
    # install.packages("ggfortify")
    library("ggfortify")
  #+END_SRC

  Following package is used for printing tables into the PDF file:
  #+BEGIN_SRC R
    # install.packages("gridExtra")
    library("gridExtra")
  #+END_SRC

  This library is used to format percentages:
  #+BEGIN_SRC R
    # install.packages("scales")
    library("scales")
  #+END_SRC

  This package can be used to export tables into the LaTeX:
  #+BEGIN_SRC R
    # install.packages("xtable")
    library("xtable")
  #+END_SRC

  Following package is able to export plots into the LaTeX (TikZ):
  #+BEGIN_SRC R
    # install.packages("tikzDevice")
    library("tikzDevice")
  #+END_SRC

  This library is used to calculate effect size (Cramer's V):
  #+BEGIN_SRC R
    # install.packages("lsr")
    library("lsr")
  #+END_SRC

  This is needed to be able to use variables instead of column names when using =dplyr=:
  #+BEGIN_SRC R
    # install.packages("lazyeval")
    library("lazyeval")
  #+END_SRC
* Data preprocessing
** Dataset loading
   Load dataset with pull requests from the CSV file:
   #+BEGIN_SRC R
     import_prs <- function(path) {
         data <- read.csv(path, header=TRUE, sep = ",", check.names=FALSE)

         # Convert strings to booleans
         data$accepted <- data$accepted == "True"
         data$submitter_is_project_member <- data$submitter_is_project_member == "True"

         data
     }

     prs <- import_prs("data.csv")

     dim(prs)

     str(prs)

     summary(prs)
   #+END_SRC
** Filter linter results
   #+BEGIN_SRC R
     prsQuality <- prs %>% select("accepted" | starts_with('results_'))

     summary(prsQuality)
   #+END_SRC
* Research Question 1
  Print the table with a summary of all projects:
  #+BEGIN_SRC R
    projects_summary <- (prs %>%
                         mutate(introduced=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x < 0, 0L, .x))),
                                fixed=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x > 0, 0L, -.x))),
                                rejected=!accepted) %>% group_by(project_name) %>% rename(Project=project_name) %>%
                         summarise(Stars=first(project_number_of_watchers), "Analyzed PRs"=n(),
                                   Accepted=percent(sum(accepted)/n()), Rejected=percent(sum(rejected)/n()),
                                   "Introduced issues"=mean(introduced, trim=0.05),
                                   "Fixed issues"=mean(fixed, trim=0.05)) %>% arrange(desc(Stars))
                         )

    print(xtable(projects_summary, type="latex", align=c("l", "|p{3.5cm}", "p{1.5cm}", "p{1.5cm}", "p{1.5cm}",
                                                        "p{1.5cm}", "p{1.5cm}", "p{1cm}|")),
          file="projects_summary.tex", include.rownames=FALSE,
          add.to.row=list(pos=list(0), command=c("\\hline")), floating=FALSE)
  #+END_SRC

  Print the scatter plot between number of stars and percentage of accepted PRs:
  #+BEGIN_SRC R
    tikz(filename="stars_and_acceptance.tex", width=10, height=6)
    ggplot(projects_summary %>% mutate_at("Accepted", function(x) readr::parse_number(x)), aes(x=Stars, y=Accepted)) + geom_point() +
        geom_smooth(method='lm') + labs(y="Accepted pull requests (\\%)")
    dev.off()
  #+END_SRC

  Print the heat map of fixed and introduced issues (PR quality overview):
  #+BEGIN_SRC R
    tikz(filename="pr_quality_heat_map.tex", width=10, height=10)
    ggplot(prs %>% mutate(introduced=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x < 0, 0L, .x))),
                          fixed=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x > 0, 0L, -.x)))),
           aes(x=introduced, y=fixed)) + xlim(-11,210) + ylim(-11,210) + geom_bin2d(binwidth=10) +
        scale_fill_gradient(trans="log10") + labs(x="Introduced issues", y="Fixed issues",
                                                  fill="Number of\npull requests")
    dev.off()
  #+END_SRC

  Print the summary about all pull request of the given language:
  #+BEGIN_SRC R
    prs %>% mutate(introduced=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x < 0, 0L, .x))),
                   fixed=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x > 0, 0L, -.x))),
                   rejected=!accepted) %>%
        summarise(Stars=mean(project_number_of_watchers), "Analyzed PRs"=n(),
                  Accepted=percent(sum(accepted)/n()), Rejected=percent(sum(rejected)/n()),
                  "Introduced issues"=mean(introduced, trim=0.05), "Fixed issues"=mean(fixed, trim=0.05))
  #+END_SRC

  Do the same but group by acceptance:
  #+BEGIN_SRC R
    prs %>% mutate(introduced=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x < 0, 0L, .x))),
                   fixed=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x > 0, 0L, -.x))),
                   rejected=!accepted) %>% group_by(accepted) %>%
        summarise(Stars=mean(project_number_of_watchers), "Analyzed PRs"=n(),
                  Accepted=percent(sum(accepted)/n()), Rejected=percent(sum(rejected)/n()),
                  "Introduced issues"=mean(introduced, trim=0.05), "Fixed issues"=mean(fixed, trim=0.05)) %>%
        print(width = Inf)
  #+END_SRC

  Print the number of pull requests that did not changed the quality:
  #+BEGIN_SRC R
    prs %>% mutate(introduced=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x < 0, 0L, .x))),
                   fixed=rowSums(mutate_all(select(., starts_with("results_")), ~if_else(.x > 0, 0L, -.x)))) %>%
        filter(introduced == 0, fixed == 0) %>% nrow
  #+END_SRC

  Summarize information about individual issues (compute maximum, minimum etc.):
  #+BEGIN_SRC R
    (issues <- prsQuality %>% group_by(accepted) %>% summarise(across(everything(),
                                                                      tibble::lst(max, min, mean, introduced_by=~sum(. > 0),
                                                                                  fixed_by=~sum(. < 0), appeared_in=~sum(. != 0)),
                                                                     .names="{.col}***{.fn}")) %>%
            tidyr::pivot_longer(cols=starts_with("results_"), names_to=c("issue", ".value"), names_sep="\\*\\*\\*") %>%
            group_by(accepted) %>% group_split() %>% bind_cols() %>% select(2:8, 11:16) %>%
            rename_with(.cols=2:7, .fn=function(x) sub("^", "rejected.", sub("\\..*", "", x))) %>%
            rename_with(.cols=8:13, .fn=function(x) sub("^", "accepted.", sub("\\..*", "", x))) %>%
            rename(issue = issue...2) %>% mutate_at("issue", function(x) sub("results_([^_]+)_", "", x)) %>%
            tidyr::extract(issue, into=c("type", "issue"), "^([^_]+)_(.*)"))
  #+END_SRC

  Print the table with summary into the PDF file:
  #+BEGIN_SRC R
    pdf("issues.pdf", height=75, width=25)
    grid.table(issues)
    dev.off()
  #+END_SRC

  Print the number of different issue that was detected in the PRs:
  #+BEGIN_SRC R
    nrow(issues)
  #+END_SRC

  Print the projects that introduced the issue:
  #+BEGIN_SRC R
    for (issue in issues$issue) {
        print(issue)
        column_name <- names(prs)[grep(paste("_", issue, sep=""), names(prs))]
        prs %>% filter_(interp(~v > 0, v=as.name(column_name))) %>% distinct(project_name) %>% print
    }
  #+END_SRC

  Summarize the issue categories:
  #+BEGIN_SRC R
    issueTypesSummary <- tibble(
      type = character(),
      introduced_total = integer(),
      introduced_by = integer(),
      fixed_total = integer(),
      fixed_by = integer()
    )
    for (type in unique(issues$type)) {
        issueTypesSummary <- issueTypesSummary %>%
            bind_rows(prs %>% select(starts_with("results_") & contains(type)) %>%
                      mutate(introduced=rowSums(mutate_all(., ~if_else(.x < 0, 0L, .x))),
                             fixed=rowSums(mutate_all(., ~if_else(.x > 0, 0L, -.x)))) %>%
                      summarize(type=type, introduced_total=sum(introduced), introduced_by=sum(introduced > 0),
                                fixed_total=sum(fixed), fixed_by=sum(fixed > 0)))
    }

    print(xtable((issueTypesSummary %>% rename(Category=type, "Introduced in total"=introduced_total,
                                               "#PRs which introduced"=introduced_by, "Fixed in total"=fixed_total,
                                               "#PRs which fixed"=fixed_by)),
                 type="latex", align=c("l", "|p{2cm}", "p{2cm}", "p{2cm}", "p{2cm}", "p{2cm}|"), digits=c(0,0,0,0,0,0)),
          file="issue_types_summary.tex", include.rownames=FALSE,
          add.to.row=list(pos=list(0), command=c("\\hline")), floating=FALSE)
  #+END_SRC

  Create a barplot with issues and their average counts in accepted/rejected pull requests:
  #+BEGIN_SRC R
    barplot(t(as.matrix(issues %>% select(accepted.mean, rejected.mean))), beside=TRUE, legend.text=TRUE,
            xlab="issue", ylab="on average in one PR")
  #+END_SRC

  List the issues sorted by the number of pull request which introduced them:
  #+BEGIN_SRC R
    issues %>% mutate(introduced_by=accepted.introduced_by + rejected.introduced_by) %>%
        arrange(desc(introduced_by)) %>% select(type, issue, introduced_by)
  #+END_SRC

  List the issues sorted by the number of pull request which fixed them:
  #+BEGIN_SRC R
    issues %>% mutate(fixed_by=accepted.fixed_by + rejected.fixed_by) %>%
        arrange(desc(fixed_by)) %>% select(type, issue, fixed_by)
  #+END_SRC

  List the issues sorted by the number of accepted pull request which introduced them:
  #+BEGIN_SRC R
    issues %>% arrange(desc(accepted.introduced_by)) %>% select(type, issue, accepted.introduced_by)
  #+END_SRC

  List the issues sorted by the number of rejected pull request which introduced them:
  #+BEGIN_SRC R
    issues %>% arrange(desc(rejected.introduced_by)) %>% select(type, issue, rejected.introduced_by)
  #+END_SRC

  List the issues sorted by the number of accepted pull request which fixed them:
  #+BEGIN_SRC R
    issues %>% arrange(desc(accepted.fixed_by)) %>% select(type, issue, accepted.fixed_by)
  #+END_SRC

  List the issues sorted by the number of rejected pull request which fixed them:
  #+BEGIN_SRC R
    issues %>% arrange(desc(rejected.fixed_by)) %>% select(type, issue, rejected.fixed_by)
  #+END_SRC

  List the issues and the percentage in how many pull requests they change the quality:
  #+BEGIN_SRC R
    issues %>% transmute(type, issue, appeared_in=(rejected.appeared_in + accepted.appeared_in)) %>%
        arrange(desc(appeared_in)) %>% mutate(percent_of_prs=percent(appeared_in/nrow(prs))) %>%
        print(n=Inf)
  #+END_SRC

  Print the issues that were fixed in the larger number of PRs then introduced.
  #+BEGIN_SRC R
    issues %>% transmute(type, issue, fixed_more_times=(accepted.fixed_by + rejected.fixed_by -
                                                        accepted.introduced_by - rejected.introduced_by)) %>%
        arrange(desc(fixed_more_times)) %>% print(n=Inf)
  #+END_SRC

  Create a barplot with issues on the x-axis and number of pull request in which the issues were fixed/introduced on the y-axis:
  #+BEGIN_SRC R
    tikz(filename="issues_appeared_in.tex", width=7, height=3)
    issues %>% transmute(type, appeared_in=100*(rejected.appeared_in + accepted.appeared_in)/nrow(prs)) %>%
        arrange(desc(appeared_in)) %>% mutate(pos=1:n()) %>%
        ggplot(aes(x=pos, y=appeared_in, fill=type)) + geom_col() + labs(x="Issues", y="Pull Requests (\\%)", fill="Types") +
        theme(axis.ticks.x=element_blank(), axis.text.x=element_blank())
    dev.off()
  #+END_SRC

  Create a scatter plot with issue types on the x-axis and number of pull request in which the issues were
  fixed/introduced on the y-axis:
  #+BEGIN_SRC R
    tikz(filename="issues_types_and_prs.tex", width=7, height=5)
    issues %>% transmute(type, appeared_in=100*(rejected.appeared_in + accepted.appeared_in)/nrow(prs)) %>%
        ggplot(aes(x=reorder(type, desc(appeared_in), mean), y=appeared_in)) + labs(x="Issue types (sorted by y-axis mean)",
                                                                                    y="Pull Requests (\\%)") + geom_point()
    dev.off()
  #+END_SRC

  Print the issue types and percentage of PRs that contained the average issue from the given category.
  #+BEGIN_SRC R
    issues %>% transmute(type, appeared_in=100*(rejected.appeared_in + accepted.appeared_in)/nrow(prs)) %>%
        group_by(type) %>% summarize(mean(appeared_in))
  #+END_SRC
* Research Question 2
  Import the issue importance from CSV files:
  #+BEGIN_SRC R
    import_issue_importance <- function(path) {
        (lapply(list.files(path=path, pattern="*.csv"),
               (function (file) read.csv(paste(path, file, sep=""), header=TRUE, sep = ",",
                                         check.names=FALSE) %>% rename_with(~sub("_ruleid.csv", "", file),
                                                                            Importance)))
        ) %>% reduce(full_join, by="Variables") %>%
              mutate_at("Variables", function(x) sub("results_([^_]+)_", "", x)) %>%
              tidyr::extract(Variables, into=c("type", "issue"), "^([^_]+)_(.*)")
    }

    issueImportance <- import_issue_importance("classification/Importances_drop/values/")

    introducedIssueImportance <- import_issue_importance("classification_introduced/Importances_drop/values/")

    fixedIssueImportance <- import_issue_importance("classification_fixed/Importances_drop/values/")
  #+END_SRC

  Sort issues by their average importance and print them:
  #+BEGIN_SRC R
    issueImportance %>% mutate(mean=rowMeans(.[,-1:-2])) %>% arrange(desc(mean)) %>% head(10) %>% print

    introducedIssueImportance %>% mutate(mean=rowMeans(.[,-1:-2])) %>% arrange(desc(mean)) %>% head(10) %>% print

    fixedIssueImportance %>% mutate(mean=rowMeans(.[,-1:-2])) %>% arrange(desc(mean)) %>% head(10) %>% print
  #+END_SRC

  Sort issues by their average importance and plot them in the barplot:
  #+BEGIN_SRC R
    plot_issue_importance <- function(issue_importance) {
        issue_importance %>% mutate(mean=rowMeans(.[,-1:-2])) %>% arrange(desc(mean)) %>% head(10) %>%
            tidyr::gather(classifier, importance, -c(type, issue, mean)) %>% ggplot() +
                geom_bar(aes(x=reorder(issue, mean), y=(100 * importance), fill=classifier), stat='identity') + coord_flip() +
                labs(x="Issues", y="Importance (\\%)", fill="Classifier") + geom_hline(yintercept=0)
    }

    tikz(filename="issue_importance.tex", width=4.5, height=3)
    plot_issue_importance(issueImportance)
    dev.off()

    plot_issue_importance(issueImportance)

    plot_issue_importance(introducedIssueImportance)

    plot_issue_importance(fixedIssueImportance)
  #+END_SRC
* Research Question 3
** PCA scatterplot
   #+BEGIN_SRC R
     set.seed(135089)
     prsSample <- prsQuality %>% sample_n(2000, replace=FALSE)

     acceptancePCA <- prcomp(prsSample %>% select(-accepted))

     (autoplot(acceptancePCA, data=prsSample, colour="accepted") +
      labs(x=paste("PC1 (", summary(acceptancePCA)$importance[2,1] * 100, "\\%)", sep=""),
           y=paste("PC2 (", summary(acceptancePCA)$importance[2,2] * 100, "\\%)", sep=""), colour="Accepted")
     )

     tikz(filename="acceptance_pca.tex", width=6, height=4)
     (autoplot(acceptancePCA, data=prsSample, colour="accepted") + xlim(-0.0025, 0.0025) + ylim(-0.01, 0.01) +
      labs(x=paste("PC1 (", summary(acceptancePCA)$importance[2,1] * 100, "\\%)", sep=""),
           y=paste("PC2 (", summary(acceptancePCA)$importance[2,2] * 100, "\\%)", sep=""), colour="Accepted")
     )
     dev.off()
   #+END_SRC
** Contingency matrices
   Define function for transforming the data into the contingency matrix:
   #+BEGIN_SRC R
     to_contingency_table <- function(prs_data) {
         ct <- data.frame((prs_data %>% select("accepted" | starts_with("results_")) %>%
                           transmute(accepted, issueTypes=rowSums(.[-1]>0)) %>% group_by(accepted) %>%
                           summarize(across(everything(), tibble::lst(introduced=~sum(.>0), didNotIntroduced=~sum(.==0)))))[,-1])
         colnames(ct) <- c("Issue introduced", "Issue not introduced")
         rownames(ct) <- c("Rejected", "Accepted")
         ct
     }
   #+END_SRC

   Define function that will be used to plot results of chi-square test of independence:
   #+BEGIN_SRC R
     chsqt_plot <- function(chsqt) {
         ggplot(data=data.frame(Frequency=c(chsqt$observed[1,1], chsqt$observed[1,2], chsqt$observed[2,1], chsqt$observed[2,2],
                                            chsqt$expected[1,1], chsqt$expected[1,2], chsqt$expected[2,1], chsqt$expected[2,2]),
                                Value=rep(c("Observed", "Expected"), each=4),
                                Quality=rep(c("Issue detected", "Without an issue"), times=4),
                                Acceptance=rep(rep(c("Rejected pull requests", "Accepted pull requests"), each=2), times=2)
                                ), aes(x=Quality, y=Frequency, fill=Value)) + geom_bar(stat="identity", position="dodge") +
             facet_grid(~ Acceptance) + labs(x="Presence of some quality issue", y="Pull request frequency")
     }
   #+END_SRC

   Define function for printing chi-square test:
   #+BEGIN_SRC R
     chsqt_print <- function(ct_name, ct) {
         print(ct_name)
         chsqtType <- chisq.test(ct)
         print(chsqtType)
         print("Observed:")
         print(chsqtType$observed)
         print("Expected:")
         print(chsqtType$expected)
         print(cramersV(ct))
         print(paste(rep("-", times=80), collapse=""))
     }
   #+END_SRC

   Does an introduction of some code quality issue in the PR affects its acceptance?
   #+BEGIN_SRC R
     qualityCT <- to_contingency_table(prs)

     chsqt_print("All PRs", qualityCT)

     tikz(filename="acceptance_ct.tex", width=10, height=6)
     chsqt_plot(chisq.test(qualityCT))
     dev.off()
   #+END_SRC

   Filter PRs that only modified some source code files and test them:
   #+BEGIN_SRC R
     only_modified <- function(data) {
         data %>% filter(modified == linted_and_modified, added == 0, deleted == 0)
     }

     qualityModCT <- to_contingency_table(only_modified(prs))

     chsqt_print("PR's that only modified some source code files", qualityModCT)

     tikz(filename="acceptance_mod_ct.tex", width=10, height=6)
     chsqt_plot(chisq.test(qualityModCT))
     dev.off()
   #+END_SRC

   Test each issue category independently:
   #+BEGIN_SRC R
     for (type in unique(issues$type)) {
         chsqt_print(type, to_contingency_table(prs %>% select(accepted, contains(paste("_", type, "_", sep="")))))
     }
   #+END_SRC

   Test each project independently:
   #+BEGIN_SRC R
     projects_chsqt <- tibble(Project=character(), pr_count=integer(), p.value=numeric(), V=numeric(),
                              observed.rejected.introduced=numeric(), expected.rejected.introduced=numeric(),
                              Independent=logical(), "Enough observations"=logical())
     for (project in unique(prs$project_name)) {
         project_prs <- prs %>% filter(project_name == project)
         ct <- to_contingency_table(project_prs)
         chsqt_print(project, ct)
         chsqt <- chisq.test(ct)
         projects_chsqt <- projects_chsqt %>% add_row(Project=project, pr_count=nrow(project_prs), p.value=chsqt$p.value,
                                                      V=cramersV(ct), observed.rejected.introduced=chsqt$observed[[1]],
                                                      expected.rejected.introduced=chsqt$expected[[1]] - chsqt$observed[[1]],
                                                      Independent=(chsqt$p.value > 0.05),
                                                      "Enough observations"=all(chsqt$expected >= 10))
     }

     projects_chsqt %>% print(width=Inf)

     count(projects_chsqt %>% filter(`Enough observations` == TRUE))

     projects_chsqt %>% filter(`Enough observations` == TRUE) %>% print(width=Inf)

     count(projects_chsqt %>% filter(`Enough observations` == TRUE, p.value < 0.05))

     projects_chsqt %>% filter(`Enough observations` == TRUE, p.value < 0.05) %>% print(width=Inf)

     projects_chsqt %>% filter(`Enough observations` == TRUE, p.value < 0.05) %>% summarize_all(mean)
   #+END_SRC
** ROC curves and AUCs
   Retrieve classifiers metrics:
   #+BEGIN_SRC R
     import_classification_metrics <- function(path) {
         files <- list.files(path=path, pattern="*.csv")
         metrics <- lapply(files, (function (file) read.csv(paste(path, file, sep=""), header=TRUE, sep = ",", check.names=FALSE)))
         names(metrics) = lapply(files, function (file) sub("_ruleid.csv", "", file))
         bind_rows(metrics, .id="Classifier")
     }

     classificationMetrics <- import_classification_metrics("classification/Metrics/")

     classificationMetrics

     classificationMetrics %>% summarise_all(mean)

     classificationMetricsIntroduced <- import_classification_metrics("classification_introduced/Metrics/")

     classificationMetricsIntroduced

     classificationMetricsFixed <- import_classification_metrics("classification_fixed/Metrics/")

     classificationMetricsFixed
   #+END_SRC

   Import ROC curves:
   #+BEGIN_SRC R
     import_roc_curves <- function(path, metrics) {
         files <- list.files(path=path, pattern="*.csv")
         rocs <- lapply(files, (function (file) read.csv(paste(path, file, sep=""), header=TRUE, sep = ",", check.names=FALSE)))
         names(rocs) = (metrics %>% transmute(names=stringr::str_c(Classifier, " (AUC=", percent(AUC_mean/100), ")")))$names
         rocs
     }

     classificationROCs <- import_roc_curves("classification/AUCs/values/", classificationMetrics)

     classificationIntroducedROCs <- import_roc_curves("classification_introduced/AUCs/values/", classificationMetricsIntroduced)

     classificationFixedROCs <- import_roc_curves("classification_fixed/AUCs/values/", classificationMetricsFixed)
   #+END_SRC

   Plot ROC curves:
   #+BEGIN_SRC R
     plot_roc_curves <- function(rocs) {
         ggplot(bind_rows(rocs, .id="Classifier"), aes(x=mean_fpr, y=mean_tpr, colour=Classifier)) + geom_line() +
             geom_abline(intercept=0, slope=1, linetype="dashed") + xlab("False Positive Rate (1 - specificity)") +
             ylab("True Positive Rate (sensitivity)")
     }

     plot_roc_curves(classificationROCs)

     plot_roc_curves(classificationIntroducedROCs)

     plot_roc_curves(classificationFixedROCs)
   #+END_SRC
* Research Question 4
  Retrieve regression metrics:
  #+BEGIN_SRC R
    import_regression_metrics <- function(path) {
        files <- list.files(path=path, pattern="*_metrics.csv")
        metrics <- lapply(files, (function (file) read.csv(paste(path, file, sep=""), header=TRUE, sep = ",", check.names=FALSE)))
        names(metrics) = lapply(files, function (file) sub("_metrics.csv", "", file))
        bind_rows(metrics, .id="Regressor")
    }

    regressionMetrics <- import_regression_metrics("regression/")

    regressionMetrics

    regressionMetricsIntroduced <- import_regression_metrics("regression_introduced/")

    regressionMetricsIntroduced

    regressionMetricsFixed <- import_regression_metrics("regression_fixed/")

    regressionMetricsFixed
  #+END_SRC

  Import predicted/actual values (regression):
  #+BEGIN_SRC R
    import_regression_plots <- function(path, metrics) {
        files <- list.files(path=path, pattern="*_predicted.csv")
        curves <- lapply(files, (function (file) read.csv(paste(path, file, sep=""), header=TRUE, sep = ",", check.names=FALSE)))
        names(curves) = (metrics %>% transmute(names=stringr::str_c(Regressor, " (R^2=", R2, ")")))$names
        curves
    }

    regressionPlots <- import_regression_plots("regression/", regressionMetrics)

    regressionPlotsIntroduced <- import_regression_plots("regression_introduced/", regressionMetricsIntroduced)

    regressionPlotsFixed <- import_regression_plots("regression_fixed/", regressionMetricsFixed)
  #+END_SRC

  Plot regression curves (predicted vs actual):
  #+BEGIN_SRC R
    plot_regression_plots <- function(curves) {
        ggplot(bind_rows(curves, .id="Regressor"), aes(x=Predicted, y=Actual, colour=Regressor)) + geom_point() +
            geom_abline(intercept=0, slope=1, linetype="dashed")
    }

    plot_regression_plots(regressionPlots)

    plot_regression_plots(regressionPlotsIntroduced)

    plot_regression_plots(regressionPlotsFixed)
  #+END_SRC

  Compute $R^2$ when considering only PRs that was closed within a month:
  #+BEGIN_SRC R
    bind_rows(regressionPlots, .id="Regressor") %>% group_by(Regressor) %>% filter(Actual < 2629800) %>%
        summarize(R2=cor(Predicted, Actual) ^ 2)
  #+END_SRC

  Print the percentage of PRs that was closed within a month:
  #+BEGIN_SRC R
    percent(nrow(prs %>% filter(time_opened < 2629800))/nrow(prs))
  #+END_SRC

  Print summary about all regression metrics:
  #+BEGIN_SRC R
    regressionMetrics %>% summarize(across(where(is.double), ~mean(.x)))

    regressionMetricsIntroduced %>% summarize(across(where(is.double), ~mean(.x)))

    regressionMetricsFixed %>% summarize(across(where(is.double), ~mean(.x)))
  #+END_SRC
* Research Question 5
  Set the working directory:
  #+BEGIN_SRC R
    setwd('~/Documents/master/results/')
  #+END_SRC

  Import all pull requests:
  #+BEGIN_SRC R
    prsAll <- list("C/C++" = import_prs("c_cpp/data.csv"), "Haskell" = import_prs("haskell/data.csv"),
                   "Java" = import_prs("java/data.csv"), "Kotlin" = import_prs("kotlin/data.csv"),
                   "Python" = import_prs("python/data.csv"))
  #+END_SRC
** Chi-square tests
   Import pull requests from all languages and run chi-square tests:
   #+BEGIN_SRC R
     prsAll %>% map(~tribble(~V, ~p, ~Type,
                             #
                             cramersV(to_contingency_table(.x)),
                             chisq.test(to_contingency_table(.x))$p.value,
                             "All",
                             #
                             cramersV(to_contingency_table(only_modified(.x))),
                             chisq.test(to_contingency_table(only_modified(.x)))$p.value,
                             "Only modified")
                    ) %>% bind_rows(.id = "Language") %>% mutate(Independent = (p > 0.05))
   #+END_SRC

   Plot the Cramer's V for all languages:
   #+BEGIN_SRC R
     tikz(filename="all_cramers_v.tex", width=8, height=6)
     chisqtAll %>% ggplot(aes(x=Type, y=V, fill=Independent)) + geom_bar(stat="identity", position="dodge") +
         facet_grid(~ Language) + ylab("Cramer's V")
     dev.off()
   #+END_SRC
** Classification
   Import classification metrics for all languages:
   #+BEGIN_SRC R
     allClassificationMetrics <- bind_rows(list(
         "C/C++" = import_classification_metrics("c_cpp/classification/Metrics/"),
         "Haskell" = import_classification_metrics("haskell/classification/Metrics/"),
         "Java" = import_classification_metrics("java/classification/Metrics/"),
         "Kotlin" = import_classification_metrics("kotlin/classification/Metrics/"),
         "Python" = import_classification_metrics("python/classification/Metrics/")), .id="Language")
   #+END_SRC

   Create box plot with /AUC mean/ for each language:
   #+BEGIN_SRC R
     tikz(filename="all_auc.tex", width=8, height=6)
     allClassificationMetrics %>% ggplot(aes(x=Language, y=AUC_mean)) + labs(y="AUC mean") +
         geom_boxplot() + geom_point(aes(col=Classifier), size=5)
     dev.off()
   #+END_SRC
** Regression
   Import regression metrics for all languages:
   #+BEGIN_SRC R
     allRegressionMetrics <- bind_rows(list(
         "C/C++" = import_regression_metrics("c_cpp/regression/"),
         "Haskell" = import_regression_metrics("haskell/regression/"),
         "Java" = import_regression_metrics("java/regression/"),
         "Kotlin" = import_regression_metrics("kotlin/regression/"),
         "Python" = import_regression_metrics("python/regression/")), .id="Language")
   #+END_SRC

   Create box plot with /MAE/ for each language:
   #+BEGIN_SRC R
     tikz(filename="all_mae.tex", width=8, height=6)
     allRegressionMetrics %>% mutate_at("MAE", function(mae) mae / 86400) %>% ggplot(aes(x=Language, y=MAE)) + labs(y="MAE (days)") +
         geom_boxplot() + geom_point(aes(col=Regressor), size=5)
     dev.off()
   #+END_SRC

   Compute the percentage of PRs that was close within first two weeks:
   #+BEGIN_SRC R
     prsAll %>% map(~(nrow(.x %>% filter(time_opened < 1209600)) / nrow(.x))) %>% print
   #+END_SRC
* Summary
  Print the total number of PRs for all languages:
  #+BEGIN_SRC R
    Reduce("+", prsAll %>% map(~nrow(.x)))
  #+END_SRC

  Print the number of accepted PRs:
  #+BEGIN_SRC R
    Reduce("+", prsAll %>% map(~nrow(.x %>% filter(accepted == TRUE))))
  #+END_SRC

  Print the number of PRs that introduced some issue:
  #+BEGIN_SRC R
    Reduce("+", prsAll %>% map(~(.x %>% mutate(introduced=rowSums(mutate_all(select(., starts_with("results_")),
                                                                             ~if_else(.x < 0, 0L, .x))),
                                               fixed=rowSums(mutate_all(select(., starts_with("results_")),
                                                                        ~if_else(.x > 0, 0L, -.x)))) %>% filter(introduced > 0) %>%
                                 nrow)))
  #+END_SRC

  Print the number of PRs that fixed some issue:
  #+BEGIN_SRC R
    Reduce("+", prsAll %>% map(~(.x %>% mutate(introduced=rowSums(mutate_all(select(., starts_with("results_")),
                                                                             ~if_else(.x < 0, 0L, .x))),
                                               fixed=rowSums(mutate_all(select(., starts_with("results_")),
                                                                        ~if_else(.x > 0, 0L, -.x)))) %>% filter(fixed > 0) %>%
                                 nrow)))
  #+END_SRC
